# The base hadoop image to use for all components.
# See this repo for image build details: https://github.com/Comcast/kube-yarn/tree/master/image
images:
  hdfs:
    repository: thecompiler1941/hdfs
    tag: v3_3.2.3
    pullPolicy: IfNotPresent
  hdfsUI:
    repository: thecompiler1941/hdfs-ui
    tag: v3.3
    pullPolicy: IfNotPresent

# Select antiAffinity as either hard or soft, default is 'soft'
# 'hard' is sugested for production setup
antiAffinity: "soft"

conf:
  coreSite:
    # fs.trash.interval: "10080"  # trash auto purge in minutes
    hadoop.http.staticuser.user: hduser
  hdfsSite:
    dfs.replication: 3  # when changing this value ensure that dataNode.replicas is equal or higher than this value
    dfs.webhdfs.enabled: true
    # dfs.datanode.du.reserved: "4294967296"  # number of bytes to reserve on disk to block hitting disk full, must be quoted for large numbers, because of gotemplate converting large numbers to float with scientific notation

hdfsUI:
  replicas: 1
  port: 8080
  hdfsUser: hduser
  service:
    type: ClusterIP
    port: 80
  resources:
    requests:
      memory: "256Mi"
      cpu: "10m"
    limits:
      memory: "2048Mi"
      cpu: "1000m"

nameNode:
  pdbMinAvailable: 1
  port: 8020
  resources:
    requests:
      memory: "256Mi"
      cpu: "10m"
    limits:
      memory: "2048Mi"
      cpu: "1000m"
  webhdfs:
    port: 9870

dataNode:
  replicas: 3  # ensure this value is higher or equal to 'conf.hdfsSite.dfs.replication'
  pdbMinAvailable: 3  # ensure to set this value before deploying
  resources:
    requests:
      memory: "256Mi"
      cpu: "10m"
    limits:
      memory: "2048Mi"
      cpu: "1000m"
  webhdfs:
    port: 9864

ingress:
  nameNode:
    enabled: false
    annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
    labels: {}
    path: /
    hosts:
    - "hdfs-namenode.local"
  dataNode:
    enabled: false
    annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
    labels: {}
    path: /
    hosts:
    - "hdfs-datanode.local"

persistence:
  nameNode:
    enabled: false
    storageClass:
    accessMode: ReadWriteOnce
    size: 50Gi
  dataNode:
    enabled: false
    storageClass:
    accessMode: ReadWriteOnce
    size: 200Gi

## ------------------------------------------------------
## Monitoring HDFS-NameNode
## ------------------------------------------------------

## Prometheus Exporter Configuration
## ref: https://prometheus.io/docs/instrumenting/exporters/
prometheus:
  ## Exporter Configuration
  ## ref: https://github.com/marcelmay/hadoop-hdfs-fsimage-exporter
  exporter:
    enabled: false
    image: marcelmay/hadoop-hdfs-fsimage-exporter:1.4.10
    port: 5556
